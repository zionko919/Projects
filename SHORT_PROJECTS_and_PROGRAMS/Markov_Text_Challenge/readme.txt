 It is a program to automate Markov model in a more efficient way. 
 The TextGenerator takes two command-line integers K and
 L, then read the input text from the standard input and builds a Markov
 model of order K from input text. Then, starting with the KGram
 consisting of the first K characters of the input text, prints out L
 characters generated by simulating a trajectory through the corresponding
 Markov chain. I assume that the text has length at least K, and also that
 L >= K.

 Using the map was very important in this program since I needed to loop
 through the KGrams and find the actual strings, vs. through an integer
 value. In a way, without the map structure, this program would not
 have been easy. Also, I would say that vector played a key part too
 because it made the assignment easier to push i characters that were
 needed to check for important conditions such as duplicates.

 My implementation is in 4 major parts.
 I have a constructor that implement the data by creating a
 symbol table with kgram keys. In which the value type of my symbol
 table is a data structure that can represent the frequency of each
 possible next character. This frequencies are tailed as if they are
 circular. So for my code:
 MModel::MModel(std::string text, int k) : _order(k) {
     std::string temp = "";
     int endIndex;
     int jIndex;
     for (unsigned int i = 0; i < text.size(); i++) {
         auto sumLambda = [](int a, int b) {
             return a + b;
         };
         endIndex = sumLambda(i, k) % text.size();
         jIndex = sumLambda(i, k);
         for (int j = i; j < jIndex; j++) {
             temp += text[j%text.size()];
         }
         _kgrams[temp][text[endIndex]] += 1;
         _kgrams[temp][11] += 1;
         temp = "";
     }
 }

 Then, I have a kOrder() function that simply returns the order K of
 the Markov Model. So for my code:
 int MModel::kOrder() {
     return _order;
 }

 For freq(), I have two of them, freq(kgram) that returns
 the number of times the kgram was found in the original text. Other one
 freq(kgram, c) returns the number of times the kgram followed by the
 character c in the original text. For both, if kgram is not found then,
 they return 0. So for my two functions:
 int MModel::freq(std::string kgram) {
     if (kgram.size() != static_cast<unsigned int>(_order)) {
         throw std::runtime_error("Error!: kgram is not of length k");
     }
     return _kgrams[kgram][11];
 }

 int MModel::freq(std::string kgram, char c) {
     if (kgram.size() != static_cast<unsigned int>(_order)) {
         throw std::runtime_error("Error!: kgram is not of length k");
     }
     InnerMarkovMap::iterator it2 = _kgrams[kgram].begin();
     if (it2 == _kgrams[kgram].end()) {
         throw std::runtime_error("Error!: kgram cannot be found");
     }
     return _kgrams[kgram][c];
 }

 Then I have this kRand(kgram) function that randomly
 generate a character. It just return a character and it must be the
 character that followed the kgram in the original text. the character
 is chosen randomly, however, the result of calling the function several
 times would mirror the frequencies of character that follows the kgram
 in the original text. For my code:
 char MModel::kRand(std::string kgram) {
     char c = '\0';
     if (kgram.size() != static_cast<unsigned int>(_order)) {
         throw std::runtime_error("Error!: kgram is not of length k");
     }
     InnerMarkovMap::iterator it2 = _kgrams[kgram].begin();
     if (it2 == _kgrams[kgram].end()) {
         throw std::runtime_error("Error!: kgram cannot be found");
     } else if (it2->second == _kgrams[kgram][11]) {
         it2++;
     }
     int total = freq(kgram);
     int random_num = rand() % total; //NOLINT
     for (; it2 != _kgrams[kgram].end(); ++it2) {
         random_num -= it2->second;
         if (random_num < 0) {
             c = it2->first;
             break;
         }
     }
     return c;
 }

